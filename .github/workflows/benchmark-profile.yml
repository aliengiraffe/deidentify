name: Benchmark & Profile

on:
  pull_request:
    types: [opened, synchronize, reopened]
  push:
    branches: [main, master]
  workflow_dispatch:

permissions:
  contents: read
  pull-requests: write
  actions: read

jobs:
  benchmark-profile:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4

    - name: Set up Go
      uses: actions/setup-go@v5
      with:
        go-version: '1.21'

    - name: Install dependencies
      run: |
        go mod download
        # Install graphviz for pprof graph generation
        sudo apt-get update
        sudo apt-get install -y graphviz

    - name: Run benchmarks with profiling
      run: |
        mkdir -p profiles
        
        # Run benchmarks with CPU profiling
        echo "Running benchmarks with CPU profiling..."
        go test -bench=BenchmarkParagraphDeidentification -benchtime=30s -cpuprofile=profiles/cpu.prof -benchmem > profiles/benchmark.txt 2>&1
        
        # Run benchmarks with memory profiling
        echo "Running benchmarks with memory profiling..."
        go test -bench=BenchmarkParagraphDeidentification -benchtime=10s -memprofile=profiles/mem.prof >> profiles/benchmark.txt 2>&1
        
        # Run parallel benchmarks
        echo "Running parallel benchmarks..."
        go test -bench=BenchmarkParagraphDeidentificationParallel -benchtime=10s >> profiles/benchmark.txt 2>&1
        
        # Display benchmark results
        echo "=== Benchmark Results ===" 
        cat profiles/benchmark.txt

    - name: Generate pprof reports
      run: |
        cd profiles
        
        # Generate CPU profile reports
        echo "Generating CPU profile reports..."
        go tool pprof -top -nodecount=20 cpu.prof > cpu_top20.txt
        go tool pprof -text cpu.prof > cpu_text.txt
        go tool pprof -svg cpu.prof > cpu_graph.svg
        go tool pprof -png cpu.prof > cpu_graph.png
        
        # Generate memory profile reports
        echo "Generating memory profile reports..."
        go tool pprof -top -nodecount=20 mem.prof > mem_top20.txt
        go tool pprof -text mem.prof > mem_text.txt
        go tool pprof -svg mem.prof > mem_graph.svg
        go tool pprof -png mem.prof > mem_graph.png
        
        # Generate focused reports on deidentify functions
        echo "Generating focused deidentify reports..."
        go tool pprof -focus=deidentify -text cpu.prof > cpu_deidentify_focused.txt
        go tool pprof -focus=deidentify -svg cpu.prof > cpu_deidentify_focused.svg

    - name: Upload profile artifacts
      uses: actions/upload-artifact@v4
      with:
        name: benchmark-profiles-${{ github.sha }}
        path: profiles/
        retention-days: 30

    - name: Comment PR with results
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          const path = require('path');
          
          // Read benchmark results
          const benchmarkResults = fs.readFileSync('profiles/benchmark.txt', 'utf8');
          const cpuTop20 = fs.readFileSync('profiles/cpu_top20.txt', 'utf8');
          const memTop20 = fs.readFileSync('profiles/mem_top20.txt', 'utf8');
          
          // Extract key metrics from benchmark output
          const throughputMatch = benchmarkResults.match(/Throughput: ([\d.]+) paragraphs\/second/);
          const meanTimeMatch = benchmarkResults.match(/Mean time per paragraph: ([\d.]+\w+)/);
          
          const throughput = throughputMatch ? throughputMatch[1] : 'N/A';
          const meanTime = meanTimeMatch ? meanTimeMatch[1] : 'N/A';
          
          // Create comment body
          const comment = `## ðŸ“Š Benchmark & Profile Results

          ### Performance Summary
          - **Throughput**: ${throughput} paragraphs/second
          - **Mean time per paragraph**: ${meanTime}
          
          ### CPU Profile (Top 20)
          \`\`\`
          ${cpuTop20.substring(0, 1000)}...
          \`\`\`
          
          ### Memory Profile (Top 20)
          \`\`\`
          ${memTop20.substring(0, 1000)}...
          \`\`\`
          
          ### ðŸ“¥ Download Full Reports
          The complete profiling artifacts are available as workflow artifacts:
          - CPU profiles (text, SVG, PNG)
          - Memory profiles (text, SVG, PNG)
          - Focused deidentify function analysis
          - Full benchmark results
          
          [Download Artifacts](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})
          
          <details>
          <summary>Full Benchmark Output</summary>
          
          \`\`\`
          ${benchmarkResults}
          \`\`\`
          </details>
          
          ---
          *Generated by Benchmark & Profile workflow*`;
          
          // Post comment
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: comment
          });

    - name: Generate summary
      run: |
        echo "## Benchmark & Profile Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        # Extract and display key metrics
        if grep -q "Throughput:" profiles/benchmark.txt; then
          echo "### Performance Metrics" >> $GITHUB_STEP_SUMMARY
          grep "Throughput:" profiles/benchmark.txt >> $GITHUB_STEP_SUMMARY
          grep "Mean time per paragraph:" profiles/benchmark.txt >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
        fi
        
        echo "### Top CPU Consumers" >> $GITHUB_STEP_SUMMARY
        echo '```' >> $GITHUB_STEP_SUMMARY
        head -n 10 profiles/cpu_top20.txt >> $GITHUB_STEP_SUMMARY
        echo '```' >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        
        echo "### Artifacts" >> $GITHUB_STEP_SUMMARY
        echo "Profile artifacts have been uploaded and are available in the workflow run." >> $GITHUB_STEP_SUMMARY